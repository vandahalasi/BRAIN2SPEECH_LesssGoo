{"cells":[{"cell_type":"code","execution_count":2,"id":"e8b2482c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8b2482c","executionInfo":{"status":"ok","timestamp":1670776519172,"user_tz":-60,"elapsed":2112,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}},"outputId":"102228e9-6711-4370-c90c-556ab11437a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"id":"eaed6820","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaed6820","executionInfo":{"status":"ok","timestamp":1670775858635,"user_tz":-60,"elapsed":342,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}},"outputId":"5499b617-28e4-4605-d721-5580a0d7d59b"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'BRAIN2SPEECH_LesssGoo' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/vandahalasi/BRAIN2SPEECH_LesssGoo.git"]},{"cell_type":"code","source":["%cd BRAIN2SPEECH_LesssGoo\n","!git pull\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnP3G2at8WyA","executionInfo":{"status":"ok","timestamp":1670775864282,"user_tz":-60,"elapsed":1126,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}},"outputId":"7b421e0a-8d2e-44f3-ba02-272b9a72ccd7"},"id":"EnP3G2at8WyA","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/BRAIN2SPEECH_LesssGoo\n","Already up to date.\n","'1D-CNN training.ipynb'\t\t\t  requirements.txt\n"," create_dataloaders.py\t\t\t  setup.py\n"," data_discovery_helpers\t\t\t  SingleWordProductionDutch\n"," data_discovery_pre_processing.ipynb\t  spectogram_dataset.py\n"," LSTM.py\t\t\t\t  training_1participant.ipynb\n"," LSTM_Train_n_Validation_notebook.ipynb   train_stats.json\n"," README.md\n"]}]},{"cell_type":"code","execution_count":4,"id":"8f7ea4df","metadata":{"id":"8f7ea4df","executionInfo":{"status":"ok","timestamp":1670775867872,"user_tz":-60,"elapsed":601,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}}},"outputs":[],"source":["!git submodule init\n","!git submodule update"]},{"cell_type":"code","source":["%cd SingleWordProductionDutch\n","from reconstruction_minimal import createAudio\n","%cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVtKZ_lYz5qb","executionInfo":{"status":"ok","timestamp":1670775871814,"user_tz":-60,"elapsed":1341,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}},"outputId":"491fc0b1-c58e-423b-c340-0d890c4f2b71"},"id":"SVtKZ_lYz5qb","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/BRAIN2SPEECH_LesssGoo/SingleWordProductionDutch\n","/content/BRAIN2SPEECH_LesssGoo\n"]}]},{"cell_type":"code","source":["!pip install ray"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KEVFFZCQnaU","executionInfo":{"status":"ok","timestamp":1670775879365,"user_tz":-60,"elapsed":4194,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}},"outputId":"8e0c99f4-18ae-46c7-96b9-ac5604cef730"},"id":"7KEVFFZCQnaU","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ray in /usr/local/lib/python3.8/dist-packages (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray) (2.23.0)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray) (1.3.1)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray) (4.3.3)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray) (3.19.6)\n","Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray) (7.1.2)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from ray) (22.1.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray) (6.0)\n","Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from ray) (1.51.1)\n","Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.8/dist-packages (from ray) (20.17.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray) (3.8.0)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from ray) (1.21.6)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray) (1.0.4)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray) (1.3.3)\n","Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray) (0.3.6)\n","Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.8/dist-packages (from virtualenv>=20.0.24->ray) (2.5.4)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray) (0.19.2)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray) (5.10.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.11.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ray) (2022.9.24)\n"]}]},{"cell_type":"code","execution_count":7,"id":"0e93fe2a","metadata":{"id":"0e93fe2a","executionInfo":{"status":"ok","timestamp":1670775890518,"user_tz":-60,"elapsed":7047,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}}},"outputs":[],"source":["#import LSTM\n","#from create_dataloaders import get_data, create_datasets, create_dataloaders, write_statistics_to_json\n","from torch.optim import Adam\n","from torch.nn import MSELoss\n","from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","from datetime import datetime\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import random_split\n","import torchvision\n","import torchvision.transforms as transforms\n","from ray import tune\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import ASHAScheduler\n","from functools import partial"]},{"cell_type":"code","source":["%cd ..\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cGkT4Gtk9b0p","executionInfo":{"status":"ok","timestamp":1670775955554,"user_tz":-60,"elapsed":277,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}},"outputId":"06c7331c-0c98-45b5-f7ac-d273cf488147"},"id":"cGkT4Gtk9b0p","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","BRAIN2SPEECH_LesssGoo  drive  sample_data\n"]}]},{"cell_type":"markdown","source":["# Utilities"],"metadata":{"id":"n5xuwG36aecI"},"id":"n5xuwG36aecI"},{"cell_type":"code","source":["import os\n","\n","import numpy as np\n","import json\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","\n","class SpectogramDataset(Dataset):   \n","    def __init__(self, data, spectogram, window, json_path):\n","        self.target_spectogram = np.array(spectogram, dtype=np.float32)\n","        self.features = data\n","        self.window = window\n","        \n","        # Opening JSON file for mean and std of training set\n","        f = open(json_path)\n","        stats = json.load(f)\n","        self.train_mean = stats[\"mean\"]\n","        self.train_std = np.array(stats[\"std\"])\n","        \n","\n","    def __len__(self):\n","        return self.features.shape[0]-self.window\n","\n","\n","    def __getitem__(self, index):\n","        # Normalization\n","        input = (self.features[index:index+self.window,:]-self.train_mean)/(self.train_std + 1e-7)\n","        return input.astype(np.float32), self.target_spectogram[index:index+self.window,:]\n","\n","def write_statistics_to_json(data):\n","    \"\"\"\n","    Saving mean and std of training data into a json file for normalization.\n","    \"\"\"\n","    stats = {}\n","    mean = np.mean(data,axis=0)\n","    std=np.std(data,axis=0)\n","    stats[\"mean\"] = mean.tolist()\n","    stats[\"std\"] = std.tolist()\n","    # Serializing json\n","    json_object = json.dumps(stats, indent=4)\n","    \n","    # Writing to sample.json\n","    with open(\"train_stats.json\", \"w\") as outfile:\n","        outfile.write(json_object)\n","\n","\n","def get_data(feat_path, list_ptcp):\n","    \"\"\"\n","    Loads features and spectograms into SpectogramDataset and creates train, \n","    validation and test dataloaders.\n","    \"\"\"\n","\n","    participants = np.array(['sub-%02d'%i for i in range(1,11)])\n","\n","    feat_names = np.load(os.path.join(feat_path,f'{participants[0]}_feat_names.npy'))\n","    feat_name_dict = {feat : idx for idx, feat in enumerate(feat_names)}\n","    for ptcp in participants:\n","        feat_names = np.load(os.path.join(feat_path,f'{ptcp}_feat_names.npy'))\n","        for feat_name in feat_names:\n","            if feat_name not in feat_name_dict.keys():\n","                feat_name_dict[feat_name] = len(feat_name_dict)\n","\n","    for idx, ptcp in enumerate(participants[list_ptcp]):\n","        spec_ptcp = np.load(os.path.join(feat_path,f'{ptcp}_spec.npy'))\n","        feat_ptcp = np.load(os.path.join(feat_path,f'{ptcp}_feat.npy'))\n","        feat_names = np.load(os.path.join(feat_path,f'{ptcp}_feat_names.npy'))\n","        right_dim_feat = np.zeros((len(feat_ptcp),len(feat_name_dict)))\n","        for i, feat_name in enumerate(feat_names):\n","            j = feat_name_dict[feat_name]\n","            right_dim_feat[:,j] = feat_ptcp[:,i]\n","\n","        train_spec, val_spec, test_spec = np.split(spec_ptcp, [int(len(spec_ptcp)*0.8), \n","                int(len(spec_ptcp)*0.85)])\n","        train_feat, val_feat, test_feat = np.split(right_dim_feat, [int(len(right_dim_feat)*0.8), \n","                int(len(right_dim_feat)*0.85)])\n","\n","        if idx == 0:\n","            spectogram_train = train_spec\n","            spectogram_val = val_spec\n","            spectogram_test = test_spec\n","            features_train = train_feat\n","            features_val = val_feat\n","            features_test = test_feat\n","\n","        spectogram_train = np.concatenate((spectogram_train, train_spec), axis=0)\n","        spectogram_val = np.concatenate((spectogram_val, val_spec), axis=0)\n","        spectogram_test = np.concatenate((spectogram_test, test_spec), axis=0)\n","        features_train = np.concatenate((features_train, train_feat), axis=0)\n","        features_val = np.concatenate((features_val, val_feat), axis=0)\n","        features_test = np.concatenate((features_test, test_feat), axis=0)\n","\n","    return spectogram_train, spectogram_val, spectogram_test, features_train, features_val, features_test\n","\n","def create_datasets(spectogram_train, spectogram_val, spectogram_test, features_train, features_val, features_test, json_path, \n","        window=3):\n","    #create a Dataset\n","    train_dataset = SpectogramDataset(features_train, spectogram_train, window, json_path)\n","    val_dataset = SpectogramDataset(features_val, spectogram_val, window, json_path)\n","    test_dataset = SpectogramDataset(features_test, spectogram_test, window, json_path)\n","\n","    return train_dataset, val_dataset, test_dataset\n","\n","def create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n","    #create dataloader\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n","    eval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = False)\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle = False)\n","\n","    return train_loader, eval_loader, test_loader\n"],"metadata":{"id":"x-fOou6Saiez","executionInfo":{"status":"ok","timestamp":1670775958354,"user_tz":-60,"elapsed":431,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}}},"id":"x-fOou6Saiez","execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"plIttiqqbW6f"},"id":"plIttiqqbW6f"},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class SpectogramLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers=2, batch_first=True):\n","        super(SpectogramLSTM, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first)\n","        self.input_size=input_size\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.linear_projection = nn.Conv1d(in_channels=self.hidden_size, \n","                out_channels=23, kernel_size=1)\n","        \n","    def forward(self, input_t):\n","        batch_size = input_t.size(0)\n","        window_size = input_t.size(1)\n","        feature_size = input_t.size(2)\n","        h0 = torch.zeros((batch_size, self.num_layers, self.hidden_size), dtype=torch.float32)\n","        c0 = torch.zeros((batch_size, self.num_layers, self.hidden_size), dtype=torch.float32)\n","\n","        output, (hn, cn) = self.lstm(input_t)\n","        \n","\n","        return self.linear_projection(output.permute(0,2,1)).permute(0,2,1)"],"metadata":{"id":"JfJPjBOVbnOP","executionInfo":{"status":"ok","timestamp":1670775962274,"user_tz":-60,"elapsed":265,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}}},"id":"JfJPjBOVbnOP","execution_count":10,"outputs":[]},{"cell_type":"markdown","id":"f25b34d8","metadata":{"id":"f25b34d8"},"source":["### Create dataloaders:"]},{"cell_type":"code","source":["import gc\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZ7bdEMEl0by","executionInfo":{"status":"ok","timestamp":1670770363026,"user_tz":-60,"elapsed":451,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}},"outputId":"a09ffe6d-1fb0-4ccd-ae20-a407ec4d2c4a"},"id":"eZ7bdEMEl0by","execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["def load_data(window_size=32,batch_size=32,participant_list=[1]):\n","  JSON_PATH=\"/content/BRAIN2SPEECH_LesssGoo/train_stats.json\"\n","  participant_list=[1]\n","  spectogram_train, spectogram_val, spectogram_test, features_train, features_val, features_test = get_data(\"/content/drive/MyDrive/BRAIN2SPEECH/features\",participant_list)\n"," \n","  if(not(os.path.isfile(JSON_PATH))):\n","    write_statistics_to_json(features_train)\n","\n","  train_dataset, val_dataset, test_dataset = create_datasets(spectogram_train, spectogram_val, \n","          spectogram_test, features_train, features_val, features_test, json_path=JSON_PATH, window=window_size)\n","  train_loader, val_loader, test_loader = create_dataloaders(train_dataset, val_dataset, \n","          test_dataset, batch_size=batch_size)\n","  \n","  return train_loader,val_loader,test_loader"],"metadata":{"id":"-eycIv5Onywa","executionInfo":{"status":"ok","timestamp":1670775968723,"user_tz":-60,"elapsed":3,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}}},"id":"-eycIv5Onywa","execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_loader, val_loader, _ = load_data()"],"metadata":{"id":"Tj4w5fhYowAl","executionInfo":{"status":"ok","timestamp":1670775979796,"user_tz":-60,"elapsed":6592,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}}},"id":"Tj4w5fhYowAl","execution_count":12,"outputs":[]},{"cell_type":"markdown","id":"02aed864","metadata":{"id":"02aed864"},"source":["## Training function"]},{"cell_type":"code","execution_count":13,"id":"aaa07099","metadata":{"id":"aaa07099","executionInfo":{"status":"ok","timestamp":1670775984394,"user_tz":-60,"elapsed":2,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}}},"outputs":[],"source":["def train(config,checkpoint_dir):\n","    sum_loss = 0\n","    val_loss = 0\n","\n","    # constant variables:\n","    EPOCH = 2\n","    JSON_PATH = r\"BRAIN2SPEECH_LesssGoo/train_stats.json\"\n","    PARTICIPANT_LIST = [1]\n","\n","    # Tuneable variables:\n","    criterion = config['criterion']()\n","    model = SpectogramLSTM(input_size=4860, hidden_size=config['hidden_size'])\n","    optimizer = config['optimizer'](model.parameters(),lr=config['lr'])\n","    \n","    #writer:\n","    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n","    writer = SummaryWriter(f\"/content/drive/MyDrive/BRAIN2SPEECH/runs/E{EPOCH}_BS{config['batch_size']}_WS{config['window_size']}_PTCP{PARTICIPANT_LIST}_{format(timestamp)}\")   \n","\n","    # training\n","    print(\"training\") \n","    for epoch in range(EPOCH):\n","        model.train()\n","        sum_loss = 0\n","        print('EPOCH {}:'.format(epoch + 1))\n","        for i, (in_t, target) in tqdm(enumerate(train_loader)):\n","            in_t=in_t.cuda()\n","            target=target.cuda()\n","            outputs = model.forward(in_t)\n","            optimizer.zero_grad()\n","            \n","            loss = criterion(outputs, target)\n","            loss.backward()\n","            \n","            optimizer.step()\n","\n","            sum_loss += loss.item()\n","\n","            log_frequency = 99\n","            if i % log_frequency == 0:\n","                last_loss = sum_loss / log_frequency\n","                print('  batch {} loss: {}'.format(i, last_loss))\n","                summary_idx = epoch * len(train_loader) + i\n","                writer.add_scalar('Loss/train', last_loss, summary_idx)\n","                writer.flush()\n","                sum_loss = 0.0\n","\n","        model.eval()\n","        val_loss=0.0\n","        val_steps = 0\n","        for in_v, target_v in val_loader:\n","            in_v=in_v.cuda()\n","            target_v=target_v.cuda()\n","\n","            with torch.no_grad():\n","                outputs = model.forward(in_v)\n","\n","            v_loss = criterion(outputs, target_v)\n","            val_loss += v_loss.item()\n","            val_steps += 1\n","        \n","        avg_vloss = val_loss / len(val_loader)\n","        print('LOSS valid {}'.format(avg_vloss))\n","\n","        writer.add_scalar('Loss/Validation', avg_vloss, epoch + 1)\n","        writer.flush()\n","\n","        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n","          torch.save((model.state_dict(), optimizer.state_dict()), checkpoint_dir)\n","\n","        tune.report(loss=(val_loss / val_steps))\n","    print(\"Finished Training\")"]},{"cell_type":"code","source":["def main(num_samples=10, max_num_epochs=1, gpus_per_trial=2):\n","    \n","    config = {\n","      \"lr\": tune.loguniform(1e-4, 1e-1),\n","      \"window_size\": tune.choice([16,32,64]),\n","      \"batch_size\": tune.choice([32,64,128]),\n","      \"hidden_size\": tune.choice([4860]),\n","      \"criterion\": tune.choice([MSELoss]),\n","      \"optimizer\": tune.choice([Adam])\n","    }\n","    scheduler = ASHAScheduler(\n","        metric=\"loss\",\n","        mode=\"min\",\n","        max_t=max_num_epochs,\n","        grace_period=1,\n","        reduction_factor=2)\n","    reporter = CLIReporter(\n","        parameter_columns=[\"lr\", \"window_size\", \"batch_size\", \"hidden_size\",\"criterion\",\"optimizer\"],\n","        metric_columns=[\"loss\", \"training_iteration\"])\n","   \n","    result = tune.run(\n","        partial(train),\n","        config=config,\n","        num_samples=num_samples,\n","        scheduler=scheduler,\n","        progress_reporter=reporter)\n","\n","    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n","    print(\"Best trial config: {}\".format(best_trial.config))\n","    print(\"Best trial final validation loss: {}\".format(\n","        best_trial.last_result[\"loss\"]))\n","    print(\"Best trial final validation accuracy: {}\".format(\n","        best_trial.last_result[\"accuracy\"]))\n","\n","    #test_acc = test_accuracy(best_trained_model, device)\n","    #print(\"Best trial test set accuracy: {}\".format(test_acc))"],"metadata":{"id":"kLGEFG5YreZK","executionInfo":{"status":"ok","timestamp":1670775987777,"user_tz":-60,"elapsed":378,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}}},"id":"kLGEFG5YreZK","execution_count":14,"outputs":[]},{"cell_type":"code","source":["main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167},"id":"Ftf6rLlNwX3w","executionInfo":{"status":"error","timestamp":1670777569463,"user_tz":-60,"elapsed":263,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}},"outputId":"4b81a0f7-4917-4b8b-d9e5-76664062f769"},"id":"Ftf6rLlNwX3w","execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"]}]},{"cell_type":"code","source":["drive.mount(\"/content/drive\", force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JHqkjQdMChKd","executionInfo":{"status":"ok","timestamp":1670776583388,"user_tz":-60,"elapsed":4536,"user":{"displayName":"Zsombor Seres","userId":"11351067920453423686"}},"outputId":"71457a3a-88f1-475c-d563-c1b12f761f7e"},"id":"JHqkjQdMChKd","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[{"file_id":"1ffhUPH-WHe1-k3FUIO29RP__AU5VHk0-","timestamp":1670527030176},{"file_id":"https://github.com/vandahalasi/BRAIN2SPEECH_LesssGoo/blob/main/LSTM_Train_n_Validation_notebook.ipynb","timestamp":1670497718065}]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}