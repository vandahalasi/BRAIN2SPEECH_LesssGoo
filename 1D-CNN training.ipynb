{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b14ef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dani\\anaconda3\\envs\\onlab\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from create_dataloaders import *\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a689ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneDConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(OneDConvNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=n_features, out_channels = 256, kernel_size=3, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features = 256)\n",
    "            #nn.Dropout(0.5)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=256, out_channels = 256, kernel_size=3, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features = 256)\n",
    "            #nn.Dropout(0.5)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=256, out_channels = 128, kernel_size=3, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features = 128)\n",
    "            #nn.Dropout(0.5)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=128, out_channels = 64, kernel_size=3, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features = 64)\n",
    "            #nn.Dropout(0.5)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels = 32, kernel_size=3, padding = 'same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features = 32)\n",
    "            #nn.Dropout(0.5)\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=32, out_channels = 30, kernel_size=8),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893c42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectogram_train, spectogram_val, spectogram_test, features_train, features_val, features_test = get_data()\n",
    "# Only need to be run if train_stats.json is missing\n",
    "# write_statistics_to_json(features_train)\n",
    "train_dataset, val_dataset, test_dataset = create_datasets(spectogram_train, spectogram_val, spectogram_test, features_train, features_val, features_test, window=30)\n",
    "train_dl,val_dl,test_dl = create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd3fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47946\n",
      "1499\n",
      "CUDA available\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(train_dl))\n",
    "epoch = 10\n",
    "window_size = 30\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available\")\n",
    "    device = \"cuda:0\"\n",
    "    device = torch.device(device)\n",
    "num_features = 4860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744016a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneDConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv1d(4860, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (layer6): Sequential(\n",
       "    (0): Conv1d(32, 30, kernel_size=(8,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OneDConvNet(num_features)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfdda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1499/1499 [03:48<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, avg training loss: 1.4600196856113177\n",
      "Validation loss: 0.02615857893420804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1499/1499 [03:51<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, avg training loss: 0.8515614729232992\n",
      "Validation loss: 0.021038213083820957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1499/1499 [03:54<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, avg training loss: 0.7019005198928815\n",
      "Validation loss: 0.02342009288008495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1499/1499 [03:49<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, avg training loss: 0.6111875451589283\n",
      "Validation loss: 0.01618587842551611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1499/1499 [04:00<00:00,  6.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,epoch+1):  # loop over the dataset multiple times\n",
    "    i=0\n",
    "    sum_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_dl, 0):\n",
    "        i = i+1\n",
    "        inputs = torch.permute(inputs, (0, 2, 1))\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += loss.item()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch: {epoch}, avg training loss: {sum_loss/len(train_dl)}\") \n",
    "    \n",
    "    for in_v, target_v in val_dl:\n",
    "            in_v= torch.permute(in_v, (0, 2, 1))\n",
    "            in_v = in_v.to(device)\n",
    "            target_v = target_v.to(device)\n",
    "            outputs = model.forward(in_v)\n",
    "            v_loss = criterion(outputs, target_v)\n",
    "            val_loss += v_loss.item()\n",
    "            \n",
    "    print(f\"Validation loss: {v_loss.item()/len(val_dl)}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058e5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:onlab]",
   "language": "python",
   "name": "conda-env-onlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
