{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea88db6-1ac9-4093-a128-d92ccf6d5a92",
   "metadata": {},
   "source": [
    "## Spectrogram autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2eeed6e-32cd-46dd-a0af-b95fffa92281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_discovery_helpers.PreProcessedData import PreProcessedData\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Tuple\n",
    "from pydantic import BaseModel\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96331eb-6086-4afa-99b9-11012d17f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_data(p_id: str, feat_path: str):\n",
    "    feats = np.load(os.path.join(feat_path,f'{p_id}_feat.npy'))\n",
    "    spec = np.load(os.path.join(feat_path,f'{p_id}_spec.npy'))\n",
    "    \n",
    "    return feats,spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b9faa1d-7449-4e28-9b1d-3d428d720def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feat shape: (29985, 1143)\n",
      "Spec shape: (29985, 23)\n"
     ]
    }
   ],
   "source": [
    "p_ids = ['sub-01', 'sub-02', 'sub-03', 'sub-04', 'sub-05', 'sub-06', 'sub-07', 'sub-08', 'sub-09', 'sub-10']\n",
    "DEFAULT_FEATURES_PATH = r'./features'\n",
    "feats, spec = load_participant_data(p_ids[0],DEFAULT_FEATURES_PATH)\n",
    "print(f\"Feat shape: {feats.shape}\")\n",
    "print(f\"Spec shape: {spec.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcfbde5c-fcc6-420a-8bc2-275087d3a0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_instances(feats:np.ndarray, spec: np.ndarray,input_window_size:int,output_window_size:int)->Tuple[np.ndarray]:\n",
    "    \"\"\"Make the input and the output for the NN.\n",
    "    \n",
    "    timeseries: timeseries vector\n",
    "    input_window_size: from have many days we want to predict the future\n",
    "    output_window_size: how many days we want to predict in the future\n",
    "    \"\"\"\n",
    "    \n",
    "    X = [] #input data for the NN\n",
    "    Y = [] #output data for the NN   \n",
    "    \n",
    "    t = feats.shape[0]\n",
    "    \n",
    "    for idx in range(t-(input_window_size+output_window_size)):\n",
    "        x = np.asarray(feats[idx:idx+input_window_size])\n",
    "        y = np.asarray(spec[(idx+input_window_size):(idx+input_window_size+output_window_size)])\n",
    "        \n",
    "        X.append(x)\n",
    "        Y.append(y[0])\n",
    "        \n",
    "    # normalization    \n",
    "    return (np.asarray(X),np.asarray(Y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "600bd261-d537-46bc-af4c-860bce9dfeab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feat shape: (29985, 1143)\n",
      "Spec shape: (29985, 23)\n",
      "X shape: (29972, 12, 1143)\n",
      "Y shape: (29972, 23)\n",
      "[[[2.22035436 2.73808935 2.85690161 ... 2.28213407 2.23484694 2.50348484]\n",
      "  [2.39475793 2.70724067 3.01786318 ... 2.22221548 2.12541089 2.29082713]\n",
      "  [3.09624351 2.53434615 3.6592359  ... 1.71764827 1.90184825 2.20471851]\n",
      "  ...\n",
      "  [3.77647414 4.51945198 2.42160424 ... 2.42756598 3.03646729 2.93255736]\n",
      "  [3.57035723 4.58016079 2.75856102 ... 3.25909295 3.51799849 3.50280557]\n",
      "  [3.5842496  4.28712111 3.15903961 ... 3.61000989 3.78155424 3.44510973]]\n",
      "\n",
      " [[2.39475793 2.70724067 3.01786318 ... 2.22221548 2.12541089 2.29082713]\n",
      "  [3.09624351 2.53434615 3.6592359  ... 1.71764827 1.90184825 2.20471851]\n",
      "  [4.02233416 2.83700801 4.48158457 ... 2.00716342 2.23391262 2.45765985]\n",
      "  ...\n",
      "  [3.57035723 4.58016079 2.75856102 ... 3.25909295 3.51799849 3.50280557]\n",
      "  [3.5842496  4.28712111 3.15903961 ... 3.61000989 3.78155424 3.44510973]\n",
      "  [2.72810797 4.10928657 3.67309008 ... 3.38809066 3.81723014 3.22110608]]\n",
      "\n",
      " [[3.09624351 2.53434615 3.6592359  ... 1.71764827 1.90184825 2.20471851]\n",
      "  [4.02233416 2.83700801 4.48158457 ... 2.00716342 2.23391262 2.45765985]\n",
      "  [4.42543006 3.13355322 4.05525528 ... 1.81529269 2.29063091 2.34098984]\n",
      "  ...\n",
      "  [3.5842496  4.28712111 3.15903961 ... 3.61000989 3.78155424 3.44510973]\n",
      "  [2.72810797 4.10928657 3.67309008 ... 3.38809066 3.81723014 3.22110608]\n",
      "  [4.65073011 6.34980963 5.66489948 ... 2.97772911 3.24220359 2.70813827]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[4.08364503 3.40064461 3.20008149 ... 1.27726302 0.89341583 1.94614305]\n",
      "  [5.59245476 4.30982389 4.10035455 ... 1.37182572 1.08656896 1.85566538]\n",
      "  [5.87228319 4.29334582 4.30554528 ... 1.54811605 1.23905195 1.86090923]\n",
      "  ...\n",
      "  [1.87501715 2.11719593 2.34212554 ... 1.98949249 2.01400478 2.54125926]\n",
      "  [2.12468515 2.5306102  2.34335207 ... 1.45747465 1.49950954 2.16354461]\n",
      "  [2.82415428 2.97499762 2.64597093 ... 1.42598519 1.45085581 2.03449133]]\n",
      "\n",
      " [[5.59245476 4.30982389 4.10035455 ... 1.37182572 1.08656896 1.85566538]\n",
      "  [5.87228319 4.29334582 4.30554528 ... 1.54811605 1.23905195 1.86090923]\n",
      "  [6.02064362 4.38613586 4.69379602 ... 1.74021313 1.53451052 1.87071031]\n",
      "  ...\n",
      "  [2.12468515 2.5306102  2.34335207 ... 1.45747465 1.49950954 2.16354461]\n",
      "  [2.82415428 2.97499762 2.64597093 ... 1.42598519 1.45085581 2.03449133]\n",
      "  [3.12136682 3.65329891 2.56902408 ... 1.53902895 1.40531888 1.88523867]]\n",
      "\n",
      " [[5.87228319 4.29334582 4.30554528 ... 1.54811605 1.23905195 1.86090923]\n",
      "  [6.02064362 4.38613586 4.69379602 ... 1.74021313 1.53451052 1.87071031]\n",
      "  [5.88117378 4.46187319 4.92659416 ... 2.20642598 2.21548872 1.63128701]\n",
      "  ...\n",
      "  [2.82415428 2.97499762 2.64597093 ... 1.42598519 1.45085581 2.03449133]\n",
      "  [3.12136682 3.65329891 2.56902408 ... 1.53902895 1.40531888 1.88523867]\n",
      "  [3.76667065 4.63441642 3.11929308 ... 1.80788637 1.80156889 1.84713761]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feat shape: {feats.shape}\")\n",
    "print(f\"Spec shape: {spec.shape}\")\n",
    "X,Y = make_timeseries_instances(feats,spec,12,1)\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"Y shape: {Y.shape}\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61c4bc52-71da-4a09-a278-5082e31ca97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X:np.ndarray,Y:np.ndarray,valid_split: float = 0.15, test_split: float = 0.15):\n",
    "    nb_samples = X.shape[0]\n",
    "    valid_size = int(nb_samples*(1-test_split-valid_split))\n",
    "    test_size = int(nb_samples*(1-test_split))\n",
    "    X_train, Y_train = X[:valid_size], Y[:valid_size]\n",
    "    X_valid, Y_valid = X[valid_size:test_size], Y[valid_size:test_size]\n",
    "    X_test, Y_test   = X[test_size:], Y[test_size:]\n",
    "    \n",
    "    return {\"train\": [X_train, Y_train],\n",
    "            \"valid\": [X_valid,Y_valid],\n",
    "            \"test\": [X_test,Y_test]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0414ebcf-9239-47d9-9859-b67f9cf09047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20980, 12, 1143)\n",
      "(20980, 23)\n",
      "(4496, 12, 1143)\n",
      "(4496, 23)\n",
      "(4496, 12, 1143)\n",
      "(4496, 23)\n"
     ]
    }
   ],
   "source": [
    "ds_dict = split_data(X,Y)\n",
    "X_train,Y_train=ds_dict[\"train\"]\n",
    "X_valid,Y_valid=ds_dict[\"valid\"]\n",
    "X_test,Y_test=ds_dict[\"test\"]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0eccac65-5dce-4e05-a9d4-db5e2e4b8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_1d_convnet(window_size, filter_length,nb_filter,nb_input_series=1, nb_outputs=1,lr=0.0001):\n",
    "\n",
    "    model = Sequential()\n",
    " \n",
    "    model.add(Conv1D(filters=nb_filter, kernel_size=filter_length, activation='relu', input_shape=(window_size, nb_input_series)))\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_outputs, activation='linear'))\n",
    "\n",
    "    optimizer=Adam(lr=lr) \n",
    "    \n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63e65eb6-ffca-4109-a84c-4b30c3c29608",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArchConfig(BaseModel):\n",
    "    window_size: int\n",
    "    filter_length: int\n",
    "    nb_filter: int\n",
    "    lr: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e0037d8-fd0a-44c2-8cb7-46214655b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainConfig(BaseModel):\n",
    "    valid_split: float\n",
    "    test_split: float\n",
    "    epochs: int\n",
    "    batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8f469ca-9dc1-4226-9f92-cb4059d133ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(feats,spec,arch_cfg,train_cfg):\n",
    "    input_channel_num = feats.shape[-1]\n",
    "    output_channel_num = spec.shape[-1]\n",
    "    print(input_channel_num)\n",
    "    print(output_channel_num)\n",
    "    X,Y = make_timeseries_instances(feats,spec,12,1)\n",
    "    ds = split_data(X, Y,train_cfg.valid_split,train_cfg.test_split)\n",
    "    \n",
    "    X_train,Y_train = ds['train']\n",
    "    model = make_1d_convnet(window_size=arch_cfg.window_size, filter_length=arch_cfg.filter_length,nb_filter=arch_cfg.nb_filter,nb_input_series=input_channel_num, nb_outputs=output_channel_num,\n",
    "                            lr=arch_cfg.lr)\n",
    "    #model.summary()\n",
    "    \n",
    "    model.fit(X_train, Y_train, epochs=train_cfg.epochs, batch_size=train_cfg.batch_size, validation_data=ds['valid'], verbose=2)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cdaea-1c03-40c0-9ed8-2a3b72ab5f59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1143\n",
      "23\n",
      "Epoch 1/30\n",
      "656/656 - 14s - loss: 25.3964 - mae: 4.6090 - val_loss: 23.2193 - val_mae: 4.4345 - 14s/epoch - 21ms/step\n",
      "Epoch 2/30\n",
      "656/656 - 7s - loss: 23.4905 - mae: 4.4107 - val_loss: 21.5617 - val_mae: 4.2436 - 7s/epoch - 10ms/step\n",
      "Epoch 3/30\n",
      "656/656 - 4s - loss: 21.8529 - mae: 4.2211 - val_loss: 19.9971 - val_mae: 4.0553 - 4s/epoch - 6ms/step\n",
      "Epoch 4/30\n",
      "656/656 - 4s - loss: 20.3060 - mae: 4.0342 - val_loss: 18.5205 - val_mae: 3.8692 - 4s/epoch - 6ms/step\n",
      "Epoch 5/30\n",
      "656/656 - 4s - loss: 18.8439 - mae: 3.8487 - val_loss: 17.1267 - val_mae: 3.6850 - 4s/epoch - 6ms/step\n",
      "Epoch 6/30\n",
      "656/656 - 4s - loss: 17.4615 - mae: 3.6655 - val_loss: 15.8091 - val_mae: 3.5021 - 4s/epoch - 6ms/step\n",
      "Epoch 7/30\n",
      "656/656 - 4s - loss: 16.1554 - mae: 3.4831 - val_loss: 14.5671 - val_mae: 3.3205 - 4s/epoch - 7ms/step\n",
      "Epoch 8/30\n",
      "656/656 - 4s - loss: 14.9239 - mae: 3.3021 - val_loss: 13.3979 - val_mae: 3.1401 - 4s/epoch - 6ms/step\n",
      "Epoch 9/30\n",
      "656/656 - 4s - loss: 13.7640 - mae: 3.1224 - val_loss: 12.2999 - val_mae: 2.9609 - 4s/epoch - 6ms/step\n",
      "Epoch 10/30\n",
      "656/656 - 4s - loss: 12.6752 - mae: 2.9438 - val_loss: 11.2721 - val_mae: 2.7828 - 4s/epoch - 6ms/step\n",
      "Epoch 11/30\n",
      "656/656 - 4s - loss: 11.6565 - mae: 2.7664 - val_loss: 10.3145 - val_mae: 2.6061 - 4s/epoch - 6ms/step\n",
      "Epoch 12/30\n",
      "656/656 - 4s - loss: 10.7071 - mae: 2.5906 - val_loss: 9.4251 - val_mae: 2.4309 - 4s/epoch - 6ms/step\n",
      "Epoch 13/30\n",
      "656/656 - 4s - loss: 9.8261 - mae: 2.4162 - val_loss: 8.6037 - val_mae: 2.2577 - 4s/epoch - 6ms/step\n",
      "Epoch 14/30\n",
      "656/656 - 4s - loss: 9.0133 - mae: 2.2448 - val_loss: 7.8501 - val_mae: 2.0887 - 4s/epoch - 6ms/step\n",
      "Epoch 15/30\n",
      "656/656 - 4s - loss: 8.2666 - mae: 2.0786 - val_loss: 7.1609 - val_mae: 1.9242 - 4s/epoch - 6ms/step\n",
      "Epoch 16/30\n",
      "656/656 - 4s - loss: 7.5850 - mae: 1.9163 - val_loss: 6.5369 - val_mae: 1.7634 - 4s/epoch - 6ms/step\n",
      "Epoch 17/30\n",
      "656/656 - 4s - loss: 6.9676 - mae: 1.7577 - val_loss: 5.9764 - val_mae: 1.6065 - 4s/epoch - 6ms/step\n",
      "Epoch 18/30\n",
      "656/656 - 4s - loss: 6.4128 - mae: 1.6055 - val_loss: 5.4763 - val_mae: 1.4567 - 4s/epoch - 6ms/step\n",
      "Epoch 19/30\n",
      "656/656 - 4s - loss: 5.9192 - mae: 1.4666 - val_loss: 5.0379 - val_mae: 1.3260 - 4s/epoch - 7ms/step\n",
      "Epoch 20/30\n",
      "656/656 - 4s - loss: 5.4851 - mae: 1.3580 - val_loss: 4.6564 - val_mae: 1.2332 - 4s/epoch - 6ms/step\n",
      "Epoch 21/30\n",
      "656/656 - 4s - loss: 5.1079 - mae: 1.2925 - val_loss: 4.3308 - val_mae: 1.1864 - 4s/epoch - 6ms/step\n",
      "Epoch 22/30\n",
      "656/656 - 4s - loss: 4.7854 - mae: 1.2665 - val_loss: 4.0576 - val_mae: 1.1735 - 4s/epoch - 6ms/step\n",
      "Epoch 23/30\n",
      "656/656 - 4s - loss: 4.5147 - mae: 1.2644 - val_loss: 3.8346 - val_mae: 1.1808 - 4s/epoch - 6ms/step\n",
      "Epoch 24/30\n",
      "656/656 - 4s - loss: 4.2939 - mae: 1.2768 - val_loss: 3.6588 - val_mae: 1.1992 - 4s/epoch - 6ms/step\n",
      "Epoch 25/30\n",
      "656/656 - 4s - loss: 4.1184 - mae: 1.2948 - val_loss: 3.5243 - val_mae: 1.2235 - 4s/epoch - 6ms/step\n",
      "Epoch 26/30\n",
      "656/656 - 4s - loss: 3.9820 - mae: 1.3166 - val_loss: 3.4252 - val_mae: 1.2505 - 4s/epoch - 7ms/step\n",
      "Epoch 27/30\n",
      "656/656 - 4s - loss: 3.8799 - mae: 1.3390 - val_loss: 3.3560 - val_mae: 1.2773 - 4s/epoch - 6ms/step\n",
      "Epoch 28/30\n",
      "656/656 - 4s - loss: 3.8064 - mae: 1.3619 - val_loss: 3.3104 - val_mae: 1.3014 - 4s/epoch - 6ms/step\n",
      "Epoch 29/30\n"
     ]
    }
   ],
   "source": [
    "arch_cfg = ArchConfig(window_size=12,filter_length=4,nb_filter=4,lr=0.0003)\n",
    "train_cfg = TrainConfig(test_split=0.15,valid_split=0.15,epochs=30,batch_size=32)\n",
    "model=train(feats,spec,arch_cfg,train_cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
